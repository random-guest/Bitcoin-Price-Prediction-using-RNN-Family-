{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi_LSTM_updated_Tunned.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.dates import DateFormatter\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "import scipy \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, layers, callbacks\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional, Conv2D,Conv1D, BatchNormalization\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from IPython.core.pylabtools import figsize\n",
        "\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "ZIqnE-1t3LpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlKkrRPxurWw"
      },
      "outputs": [],
      "source": [
        "!pip install Historic-Crypto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from Historic_Crypto import HistoricalData"
      ],
      "metadata": {
        "id": "duP3WefmvoJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "btc_historicals = HistoricalData('BTC-USD',86400,'2021-01-01-00-00', '2022-05-30-00-00').retrieve_data() # cyrpto name, number of seconds, start date, end date\n"
      ],
      "metadata": {
        "id": "mXFZVRlFvxAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "btc_historicals.shape"
      ],
      "metadata": {
        "id": "bB36viuAwnr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "btc_historicals.tail()"
      ],
      "metadata": {
        "id": "-QepeTnmyIfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out variables\n",
        "btc_historicals.dtypes"
      ],
      "metadata": {
        "id": "wEBYs9iyygbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tst = btc_historicals"
      ],
      "metadata": {
        "id": "8AvL9iDB0Ajo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Null Values:',tst.isnull().values.sum())\n",
        "print('If any NA values:', tst.isnull().values.any())"
      ],
      "metadata": {
        "id": "8CWBQogH8Dvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create variable '‘TOMORROW_CLOSE’' which shifts 'Close' up by 1\n",
        "tst['TOMORROW_CLOSE'] = tst['close'].shift(-1,fill_value=0)"
      ],
      "metadata": {
        "id": "dhxMK0DoyiIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop last row because we shifted value (remember this when you add your forecasting data)\n",
        "tst.drop(tst.tail(1).index,inplace=True) "
      ],
      "metadata": {
        "id": "tIyv8Sikzy_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop close column, since we created new ‘TOMORROW_CLOSE’\n",
        "tst = tst.drop(columns=['close'])"
      ],
      "metadata": {
        "id": "Vb8CFnmzy1vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tst.head()"
      ],
      "metadata": {
        "id": "Ee1SrZN3y9zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tst.shape"
      ],
      "metadata": {
        "id": "bmfjRuDozBTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train data (90%) and test data (10%)\n",
        "\n",
        "train_size = int(len(tst)*0.90)\n",
        "train_dataset, test_dataset = tst.iloc[:train_size],tst.iloc[train_size:]\n"
      ],
      "metadata": {
        "id": "vaD-dLKTzJbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.head()"
      ],
      "metadata": {
        "id": "yIvQhz7xpYkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train data to X and y\n",
        "X_train = train_dataset.drop('TOMORROW_CLOSE', axis = 1)\n",
        "y_train = train_dataset.loc[:,['TOMORROW_CLOSE']]\n",
        "\n",
        "# Split test data to X and y\n",
        "X_test = test_dataset.drop('TOMORROW_CLOSE', axis = 1)\n",
        "y_test = test_dataset.loc[:,['TOMORROW_CLOSE']]"
      ],
      "metadata": {
        "id": "mHMzSSQ_24Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "fNUixtLJm6mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#Plot train and test data\n",
        "plt.figure(figsize = (12, 6))\n",
        "plt.rcParams['figure.dpi'] = 360\n",
        "plt.plot(train_dataset.TOMORROW_CLOSE)\n",
        "plt.plot(test_dataset.TOMORROW_CLOSE)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close value (US$)')\n",
        "plt.legend(['Train set', 'Test set'], loc='upper left')\n",
        "print('Dimension of train data: ',train_dataset.shape)\n",
        "print('Dimension of test data: ', test_dataset.shape)\n",
        "'''"
      ],
      "metadata": {
        "id": "hF4OcMzB3D1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Different scaler for input and output ----> Normalizate the data\n",
        "scaler_x = MinMaxScaler(feature_range = (-1,1))\n",
        "scaler_y = MinMaxScaler(feature_range = (-1,1))\n",
        "\n",
        "# Fit the scaler using available training data\n",
        "input_scaler = scaler_x.fit(X_train)\n",
        "output_scaler = scaler_y.fit(y_train)\n",
        "\n",
        "# Apply the scaler to training data\n",
        "train_y_norm = output_scaler.transform(y_train)\n",
        "train_x_norm = input_scaler.transform(X_train)\n",
        "\n",
        "# Apply the scaler to test data\n",
        "test_y_norm = output_scaler.transform(y_test)\n",
        "test_x_norm = input_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "XhyiYytM3S-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 3 dimensional data set \n",
        "def threeD_dataset (X, y, time_steps = 1):\n",
        "    Xs, ys = [], []\n",
        "    \n",
        "    for i in range(len(X)-time_steps):\n",
        "        v = X[i:i+time_steps, :]\n",
        "        Xs.append(v)\n",
        "        ys.append(y[i+time_steps])\n",
        "        \n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "\n",
        "TIME_STEPS = 15 # which means the model will make predictions of ‘TOMORROW_CLOSE’ based on the input from the 10 previous days or future days bi-lstm or bi-gru\n",
        "\n",
        "X_test, y_test = threeD_dataset(test_x_norm, test_y_norm, TIME_STEPS)\n",
        "X_train, y_train = threeD_dataset(train_x_norm, train_y_norm, TIME_STEPS)\n",
        "print('X_train.shape: ', X_train.shape)\n",
        "print('y_train.shape: ', y_train.shape)\n",
        "print('X_test.shape: ', X_test.shape) \n",
        "print('y_test.shape: ', y_test.shape)"
      ],
      "metadata": {
        "id": "_yxSLwrm3efn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create BiLSTM model\n",
        "def create_model_bilstm():\n",
        "    model = Sequential()\n",
        "    # First layer of BiLSTM\n",
        "    model.add(Bidirectional(LSTM(units = 128, return_sequences=False), input_shape=[X_train.shape[1], X_train.shape[2]])) \n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001)) # use Adam with default parameters, learning rate, ...\n",
        "    return model"
      ],
      "metadata": {
        "id": "NOhFjCaC3wM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bi_lstm = create_model_bilstm()"
      ],
      "metadata": {
        "id": "x-1Fc8hc4Nw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the summary of our baby model\n",
        "model_bi_lstm.summary()"
      ],
      "metadata": {
        "id": "QvyWxytS4Pg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Fit the model !\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10) # use early stop technique to stop the training process if the val loss didn't improve for 10 epochs\n",
        "\n",
        "# decaying lr on every 2nd epoch by 1%\n",
        "def scheduler(epoch, lr):\n",
        "    rate =  1 - 0.01 \n",
        "    if epoch%2 == 0:\n",
        "        return lr*rate\n",
        "    return lr\n",
        "\n",
        "LRscheduler = LearningRateScheduler(scheduler)\n",
        "callbacks_list = [early_stop, LRscheduler]\n",
        "'''\n",
        "\n",
        "#,callbacks=callbacks_list\n",
        "history_bi_lstm = model_bi_lstm.fit(X_train, y_train, epochs = 80, validation_split = 0.2,batch_size = 32, shuffle = False) # no shuffer , as its time series data"
      ],
      "metadata": {
        "id": "HsWs4MNL4RuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot train and validation loss\n",
        "def plot_loss (history, model_name):\n",
        "    plt.figure(figsize = (10, 6))\n",
        "    plt.rcParams['figure.dpi'] = 360\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Train vs Validation Loss for ' + model_name)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Train loss', 'Validation loss'], loc='upper right')\n",
        "    \n",
        "plot_loss (history_bi_lstm, 'Bi-LSTM')"
      ],
      "metadata": {
        "id": "zkd3oqts4anP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Afte 30 epochs, the validation errors starts to rise, which is a sign of over fitting, therefore, one has to stop the training process at 30 epochs.**"
      ],
      "metadata": {
        "id": "8c3y71jpqXIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = scaler_y.inverse_transform(y_test)\n",
        "y_train = scaler_y.inverse_transform(y_train)"
      ],
      "metadata": {
        "id": "6y6yIrED4_B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model):\n",
        "    prediction = model.predict(X_test)\n",
        "    prediction = scaler_y.inverse_transform(prediction)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "afyw6NSrNjKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_bi_lstm = prediction(model_bi_lstm)"
      ],
      "metadata": {
        "id": "gAEBUr__NlXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define a function to calculate MAE and RMSE\n",
        "def evaluate_prediction(predictions, actual, model_name):\n",
        "    errors = predictions - actual\n",
        "    mse = np.square(errors).mean()\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = np.abs(errors).mean()\n",
        "\n",
        "    print(model_name + ':')\n",
        "    print('Mean Absolute Error: {:.4f}'.format(mae))\n",
        "    print('Root Mean Square Error: {:.4f}'.format(rmse))\n",
        "    print('')"
      ],
      "metadata": {
        "id": "MvsFAOhlNqow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_prediction(prediction_bi_lstm, y_test, 'Bi-LSTM')"
      ],
      "metadata": {
        "id": "xlZLERJqNtPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828fa7fc-c729-44f6-dcce-5e47c2318ea5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bi-LSTM:\n",
            "Mean Absolute Error: 1197.1455\n",
            "Root Mean Square Error: 1668.2546\n",
            "\n"
          ]
        }
      ]
    }
  ]
}